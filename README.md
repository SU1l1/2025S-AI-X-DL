# ì§ì¥ì¸ ë¼ì´í”„ìŠ¤íƒ€ì¼ ê¸°ë°˜ ìŠ¤íŠ¸ë ˆìŠ¤ ì—°ê´€ê´€ê³„ ì˜ˆì¸¡


## ğŸ‘¨â€ğŸ’» íŒ€ì› ì†Œê°œ

| í•™ë¶€                         | ì´ë¦„   | í•™ë²ˆ        | ì´ë©”ì¼                      |
|------------------------------|--------|-------------|-----------------------------|
| ì „ìê³µí•™ë¶€                   | ì´ìˆ˜í˜¸ | 2020053909  | dltngh2001@hanyang.ac.kr    |
| ë¡œë´‡ê³µí•™ê³¼                   | ì†ì˜í›ˆ | 2020031276  | top21young@hanyang.ac.kr    |
| ì°¨ì„¸ëŒ€ë°˜ë„ì²´ìœµí•©ê³µí•™ë¶€        | ë°•ìŠ¹ìš° | 2021073863  | seungwo7@hanyang.ac.kr      |
| ë°”ì´ì˜¤ì‹ ì•½ìœµí•©í•™ë¶€ ë¶„ìì˜ì•½ì „ê³µ| ì‹ ë™ìš± | 2022016680  | hy2022016680@hanyang.ac.kr  |


## ğŸ“Œ í”„ë¡œì íŠ¸ ê°œìš”
- ì§ì¥ì¸ ìŠ¤íŠ¸ë ˆìŠ¤ ë°ì´í„°ì…‹ì„ ë°”íƒ•ìœ¼ë¡œ ì–´ë–¤ ìš”ì¸ì´ ê°€ì¥ ìŠ¤íŠ¸ë ˆìŠ¤ì™€ ì—°ê´€ì´ ë†’ì€ì§€ ë¶„ì„í•˜ê³  ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìŠ¤íŠ¸ë ˆìŠ¤ ì§€ìˆ˜ë¥¼ ì˜ˆì¸¡í•œë‹¤.

## ğŸ·ï¸ ëª©ì 
### ì§ì¥ì¸ ë¼ì´í”„ìŠ¤íƒ€ì¼ê³¼ ìŠ¤íŠ¸ë ˆìŠ¤ ê°„ì˜ ì—°ê´€ê´€ê³„ ë¶„ì„
- ë³¸ í”„ë¡œì íŠ¸ì—ì„œëŠ” ì§ì¥ì¸ì˜ ê·¼ë¬´ ì‹œê°„, ì›Œë¼ë°¸ ì§€í‘œ(ì¬íƒ ê·¼ë¬´ ì—¬ë¶€, íœ´ì‹ ì‹œê°„ í™•ë³´ ì •ë„ ë“±), ì—…ë¬´ ê°•ë„(í”„ë¡œì íŠ¸ ìˆ˜, ë§ˆê° ë¹ˆë„ ë“±) ë° ìƒí™œ ìŠµê´€(ìš´ë™ ë¹ˆë„, ìˆ˜ë©´ ì‹œê°„, ì‹ì‚¬ íŒ¨í„´ ë“±)ê³¼ ìŠ¤íŠ¸ë ˆìŠ¤ ì§€ìˆ˜ ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ ë¶„ì„.

- ê° ë¼ì´í”„ìŠ¤íƒ€ì¼ ë³€ìˆ˜ì™€ ìŠ¤íŠ¸ë ˆìŠ¤ ì§€ìˆ˜ ì‚¬ì´ì˜ ìƒê´€ê³„ìˆ˜ë¥¼ ê³„ì‚°í•˜ê³ , íšŒê·€ ë¶„ì„ ë° í†µê³„ ê²€ì •ì„ í†µí•´ ì–´ë–¤ ìš”ì†Œê°€ ìŠ¤íŠ¸ë ˆìŠ¤ì— ì–¼ë§ˆë‚˜ í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ íŒŒì•…í•  ì˜ˆì •.

- ì´ë¥¼ í†µí•´ â€œì£¼ë‹¹ 50ì‹œê°„ ì´ìƒ ê·¼ë¬´ ì‹œ ìŠ¤íŠ¸ë ˆìŠ¤ ì§€ìˆ˜ê°€ ìœ ì˜ë¯¸í•˜ê²Œ ìƒìŠ¹í•˜ëŠ”ê°€?â€ í˜¹ì€ â€œìš´ë™ ë¹ˆë„ê°€ ë†’ì€ ê·¸ë£¹ì€ ì „ë°˜ì ìœ¼ë¡œ ë‚®ì€ ìŠ¤íŠ¸ë ˆìŠ¤ ì§€ìˆ˜ë¥¼ ë³´ì´ëŠ”ê°€?â€ì™€ ê°™ì€ êµ¬ì²´ì  ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œ.

### ë¼ì´í”„ìŠ¤íƒ€ì¼ì— ë”°ë¥¸ ìŠ¤íŠ¸ë ˆìŠ¤ ì˜ˆì¸¡
- ì•ì„œ ì •ì˜í•œ ê·¼ë¬´ ì‹œê°„, ì›Œë¼ë°¸ ì§€í‘œ, ì—…ë¬´ ê°•ë„, ìƒí™œ ìŠµê´€ ë“±ì˜ ì§€í‘œë¥¼ ì…ë ¥ìœ¼ë¡œ í•˜ì—¬, ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ í™œìš©í•´ ì§ì¥ì¸ì´ ëŠë¼ëŠ” ìŠ¤íŠ¸ë ˆìŠ¤ ê°•ë„ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆì„ì§€ë¥¼ íƒêµ¬.

- ì´ë¥¼ í†µí•´ â€œì´ ì§€í‘œë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ê°œì¸ë³„ ìŠ¤íŠ¸ë ˆìŠ¤ ê°•ë„ë¥¼ ì–´ëŠ ì •ë„ ì •í™•ë„ë¡œ ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ”ê°€?â€ë¥¼ í™•ì¸í•˜ê³ , ì˜ˆì¸¡ ê²°ê³¼ê°€ ìœ ì˜ë¯¸í•  ê²½ìš° ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë ˆìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ê°œë°œì˜ ê°€ëŠ¥ì„±ì„ ëª¨ìƒ‰í•¨.

## ğŸ“ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ êµ¬ì¡°

![aixproject](https://github.com/user-attachments/assets/e9660967-eccd-4a41-ac86-eebd07b82a2b)


### ğŸ“„ íŒŒì¼ ì„¤ëª…

- **train.csv**  
  - Kaggleì—ì„œ ìˆ˜ì§‘ëœ ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë ¨ ë°ì´í„°ì…‹
  - ì „ì²˜ë¦¬ í›„ ë¶„ì„ ë° ëª¨ë¸ë§ì— ì‚¬ìš©ë¨.

- **rf_top_model.pkl**  
  - Random Forest ê¸°ë°˜ì˜ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ê²°ê³¼ ì €ì¥ íŒŒì¼
  - ì¤‘ìš” í”¼ì²˜ 3ê°œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸

- **stress_analysis.ipynb**  
  - Google Colabì—ì„œ ì‹¤í–‰ë˜ëŠ” ë©”ì¸ ë…¸íŠ¸ë¶ íŒŒì¼
  - ë°ì´í„° ì „ì²˜ë¦¬, EDA, ëª¨ë¸ í•™ìŠµ, í‰ê°€, ì‹œê°í™” ë“±ì´ í¬í•¨ë¨.


### ğŸ“‚ ë°ì´í„°ì…‹ê³¼ í”¼ì²˜êµ¬ì„±

- **ì¶œì²˜:** [Kaggle: employees-stress-level-dataset](https://www.kaggle.com/datasets/chanchalagorale/employees-stress-level-dataset/data)

| í”¼ì²˜ëª…                    | ì„¤ëª…                                 | ì˜ˆì‹œ                                            |
|---------------------------|--------------------------------------|-------------------------------------------------|
| Employee_Id               | ì§ì› ID                              | 1001, 1002, ...                                 |
| Avg_Working_Hours_Per_Day | í•˜ë£¨ í‰ê·  ê·¼ë¬´ ì‹œê°„                   | 8, 9, 10                                        |
| Work_From                 | ê·¼ë¬´ ì¥ì†Œ                            | Home(ì¬íƒ), Office(ì‚¬ë¬´ì‹¤), Hybrid(í˜¼í•©)         |
| Work_Pressure             | ì—…ë¬´ ì••ë°•(ê°•ë„)                      | High, Medium, Low                               |
| Manager_Support           | ê´€ë¦¬ì ì§€ì› ìˆ˜ì¤€                     | Excellent, Good, Poor                           |
| Sleeping_Habit            | ìˆ˜ë©´ ìŠµê´€                            | Good, Average, Poor                             |
| Exercise_Habit            | ìš´ë™ ìŠµê´€                            | Regular, Occasionally, None                     |
| Job_Satisfaction          | ì§ë¬´ ë§Œì¡±ë„                          | High, Medium, Low                               |
| Work_Life_Balance         | ì›Œë¼ë°¸(ì¼ê³¼ ì‚¶ì˜ ê· í˜•)               | Yes(ê· í˜• ìœ ì§€), No(ê· í˜• ë¯¸í¡)                   |
| Social_Person             | ì‚¬êµì„± ì •ë„                          | Yes(í™œë°œ), No(ë¹„í™œë°œ)                           |
| Lives_With_Family         | ê°€ì¡±ê³¼ ë™ê±° ì—¬ë¶€                     | Yes(ë™ê±°), No(ë¯¸ë™ê±°)                           |
| Working_State             | ê·¼ë¬´/ê±°ì£¼ ì§€ì—­(ì£¼ ê±°ì£¼ì§€)           | Delhi, Pune, Hyderabad, Karnataka ë“±            |
| Stress_Level              | ìŠ¤íŠ¸ë ˆìŠ¤ ìˆ˜ì¤€ (1~5 ì •ìˆ˜, ì˜ˆì¸¡ íƒ€ê²Ÿ)  | 1, 2, 3, 4, 5                                   |

- í´ë˜ìŠ¤ ë¶ˆê· í˜• í™•ì¸
  
![í´ë˜ìŠ¤ë¶ˆê· í˜•](https://github.com/user-attachments/assets/81f899cd-7875-41fe-87bf-d7b2fc5bd701)

ê²°ê³¼: 1~5 ë ˆë²¨ì´ ê±°ì˜ ë™ì¼í•œ ë¹ˆë„ë¡œ ë¶„í¬í•˜ê³  ìˆì–´ì„œ í´ë˜ìŠ¤ ë¶ˆê· í˜• ìš°ë ¤ëŠ” ì ìŒ.

- ì„ í˜• ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
  
![ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ](https://github.com/user-attachments/assets/b8760d8b-f76c-4d94-a148-3fc48a98dba7)


ê²°ê³¼: Sleeping_Habit ê³¼ Exercise_Habit Featureê°€ Stress_Levelì— ëŒ€í•´ íƒ€ Feature ëŒ€ë¹„ ë†’ì€ ì—°ê´€ì„±ì´ ë‚˜íƒ€ë‚¨.


## ğŸ› ï¸ ì‚¬ìš© ê¸°ìˆ 
- Python (Pandas, Numpy, Scikit-learn, Matplotlib/Seaborn)
- (ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬: XGBoost, LightGBM, etc.)

## ğŸ“ RandomForest ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ìŠ¤íŠ¸ë ˆìŠ¤ ì§€ìˆ˜ ì˜ˆì¸¡

### í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„ë¦¬

ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•´ ë°ì´í„°ë¥¼ í•™ìŠµìš©ê³¼ ê²€ì¦ìš©ìœ¼ë¡œ ë¶„ë¦¬í•¨. í´ë˜ìŠ¤ ë¶ˆê· í˜•ì„ ê³ ë ¤í•´ `stratify` ì˜µì…˜ì„ ì‚¬ìš©í•¨.

```python
X_train, X_val, y_train, y_val = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)
```


---

### ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬ì„±

ìˆ˜ì¹˜í˜• ë³€ìˆ˜ëŠ” `StandardScaler`ë¡œ ì •ê·œí™”í•˜ê³ , ë²”ì£¼í˜• ë³€ìˆ˜ëŠ” `OneHotEncoder`ë¡œ ì›-í•« ì¸ì½”ë”© ì§„í–‰. `ColumnTransformer`ë¥¼ ì‚¬ìš©í•´ ë‘ ê°€ì§€ ì „ì²˜ë¦¬ë¥¼ ë³‘ë ¬ë¡œ ì ìš©í•¨.

```python
numeric_cols = [
    'Avg_Working_Hours_Per_Day','Work_Pressure','Manager_Support',
    'Sleeping_Habit','Exercise_Habit','Job_Satisfaction','Social_Person'
]
categorical_cols = [
    'Work_From','Work_Life_Balance','Lives_With_Family','Working_State'
]

numeric_transformer = StandardScaler()
categorical_transformer = OneHotEncoder(drop='first', sparse_output=False)

preprocessor = ColumnTransformer([
    ('num', numeric_transformer, numeric_cols),
    ('cat', categorical_transformer, categorical_cols)
])
```


---

### ëª¨ë¸ íŒŒì´í”„ë¼ì¸ êµ¬ì„± ë° í•™ìŠµ

ì „ì²˜ë¦¬ì™€ ëœë¤ í¬ë ˆìŠ¤íŠ¸ ë¶„ë¥˜ê¸°ë¥¼ í•˜ë‚˜ì˜ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ë¬¶ì–´ í•™ìŠµí•¨. ëœë¤ í¬ë ˆìŠ¤íŠ¸ëŠ” 200ê°œì˜ íŠ¸ë¦¬ë¥¼ ì‚¬ìš©í•˜ë©°, ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•´ `n_jobs=-1`ë¡œ ì„¤ì •í•¨.

```python
clf = Pipeline([
    ('preproc', preprocessor),
    ('rf', RandomForestClassifier(
        n_estimators=200,
        max_depth=None,
        random_state=42,
        n_jobs=-1
    ))
])

clf.fit(X_train, y_train)
```


---

### ëª¨ë¸ í‰ê°€

ê²€ì¦ ë°ì´í„°ì— ëŒ€í•´ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  ì •í™•ë„ì™€ ë¶„ë¥˜ ë¦¬í¬íŠ¸ë¥¼ ì¶œë ¥.

```python
y_pred = clf.predict(X_val)
print(f"Validation Accuracy: {accuracy_score(y_val, y_pred):.4f}\n")
print("Classification Report:")
print(classification_report(y_val, y_pred))
```


---

###  RandomForest ëª¨ë¸ì„ ì´ìš©í•œ ì˜ˆì¸¡ ê²°ê³¼
**Accuracy:** `0.2083`  
<summary>ğŸ“‹ Classification Report</summary>

              precision    recall  f1-score   support

           1       0.23      0.23      0.23       122
           2       0.24      0.25      0.25       119
           3       0.20      0.18      0.19       118
           4       0.17      0.17      0.17       120
           5       0.20      0.21      0.21       121

    accuracy                           0.21       600
    macro avg       0.21     0.21      0.21       600
    weighted avg    0.21     0.21      0.21       600
 
<summary>ğŸ”¢ Confusion Matrix</summary>

     28 18 26 23 27
     17 30 22 25 25
     28 24 21 21 24
     28 25 19 20 28
     23 26 19 27 26

**ì£¼ìš” ê¸°ë²•:**

- ColumnTransformerë¥¼ í™œìš©í•œ ì²´ê³„ì  ì „ì²˜ë¦¬
- ìˆ˜ì¹˜í˜• ë³€ìˆ˜: StandardScaler ì ìš©
- ë²”ì£¼í˜• ë³€ìˆ˜: OneHotEncoder (drop='first') ì ìš©
- Pipelineìœ¼ë¡œ ì „ì²˜ë¦¬ì™€ ëª¨ë¸ í†µí•©
- RandomForest 200ê°œ íŠ¸ë¦¬ ì‚¬ìš©


## ê²°ê³¼: 
### 20.83 %ì˜ ì •í™•ë„ëŠ” ë¬´ì‘ìœ„ë¡œ ë‹µì„ ì°ì„ ê²½ìš° ì •ë‹µì¼ í™•ë¥ ì´ 20 %ì¸ ì ì„ ê°ì•ˆí•˜ë©´, ì‹¬ê°í•˜ê²Œ ë‚®ì€ ìˆ˜ì¹˜ì„.
### ì´ì— ë”°ë¼ ë³¸ íŒ€ì€, ì•Œê³ ë¦¬ì¦˜ê³¼ ì „ì²˜ë¦¬, Feature Engineering ê´€ì ì—ì„œ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ì—¬ ì •í™•ë„ í–¥ìƒì„ ì‹œë„í•´ë³´ê¸°ë¡œ í•¨.

## ğŸš© ì •í™•ë„ í–¥ìƒ

### 1. **ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ ë³€ê²½**
   
#### ğŸ§ª ì‹¤í—˜í•œ ëª¨ë¸ ë° íŠ¹ì§• ìš”ì•½

| ëª¨ë¸              | ì£¼ìš” íŠ¹ì§• ìš”ì•½                                           |
|-------------------|-----------------------------------------------------------|
| LogisticRegression | ì„ í˜• ëª¨ë¸, ë¹ ë¥´ê³  ê°„ë‹¨. `class_weight='balanced'` ì ìš© |
| RandomForest       | ë¹„ì„ í˜• ëª¨ë¸, ë³€ìˆ˜ ì¤‘ìš”ë„ íŒŒì•… ìš©ì´                      |
| CatBoost           | ë¹ ë¥´ê³  íŠœë‹ ë‚´ì„± ê°•í•¨, ë²”ì£¼í˜• ìë™ ì²˜ë¦¬ ê°€ëŠ¥            |
| XGBoost            | ì •ë°€í•œ ì˜ˆì¸¡, ë¶€ìŠ¤íŒ… ê³„ì—´ ëŒ€í‘œ ëª¨ë¸                      |
| MLPClassifier      | ì‹ ê²½ë§ ê¸°ë°˜, ë¹„ì„ í˜• í•™ìŠµ ê°€ëŠ¥                           |
| SVM                | ê²°ì • ê²½ê³„ ê¸°ë°˜, ì†Œê·œëª¨ì— ì í•©                           |
| LDA                | ì„ í˜• ë¶„ë¦¬ ê¸°ë°˜, í•´ì„ë ¥ ìš°ìˆ˜                              |

---

### ëª¨ë¸ë³„ ê²°ê³¼

#### ğŸ”¹ Logistic Regression  
**Accuracy:** `0.18`  
<summary>ğŸ“‹ Classification Report</summary>

              precision    recall  f1-score   support

           0       0.17      0.11      0.13       122
           1       0.18      0.26      0.22       119
           2       0.22      0.02      0.03       118
           3       0.17      0.23      0.20       120
           4       0.19      0.29      0.23       121

    accuracy                           0.18       600
    macro avg      0.19      0.18      0.16       600
    weighted avg   0.19      0.18      0.16       600


<summary>ğŸ”¢ Confusion Matrix</summary>

      6 35 11 37 33
      3 33 11 43 29
     11 30  6 27 44
      7 35 12 30 36
      9 44  2 33 33

---

#### ğŸŒ² Random Forest  
**Accuracy:** `0.195`  
<summary>ğŸ“‹ Classification Report</summary>

               precision    recall  f1-score   support
           0       0.25      0.29      0.27       122
           1       0.12      0.12      0.12       119
           2       0.21      0.21      0.21       118
           3       0.17      0.16      0.17       120
           4       0.21      0.20      0.20       121

    accuracy                           0.20       600
    macro avg      0.19      0.19      0.19       600
    weighted avg   0.19      0.20      0.19       600

<summary>ğŸ”¢ Confusion Matrix</summary>

     35 29 19 21 18
     32 14 25 20 28
     26 23 25 21 23
     21 26 31 19 23
     25 26 17 29 24

---

#### ğŸ± CatBoost  
**Accuracy:** `0.1983333`  
<summary>ğŸ“‹ Classification Report</summary>

               precision    recall  f1-score   support

           0       0.25      0.27      0.26       122
           1       0.17      0.16      0.16       119
           2       0.22      0.19      0.21       118
           3       0.16      0.15      0.16       120
           4       0.18      0.21      0.20       121

    accuracy                           0.20       600
    macro avg      0.20      0.20      0.20       600
    weighted avg   0.20      0.20      0.20       600

<summary>ğŸ”¢ Confusion Matrix</summary>

     33 19 21 21 28
     26 19 22 23 29
     29 25 23 20 21
     21 24 20 18 37
     21 26 20 28 26

---

#### ğŸš€ XGBoost  
**Accuracy:** `0.2366666`  
<summary>ğŸ“‹ Classification Report</summary>

               precision    recall  f1-score   support

           0       0.32      0.35      0.33       122
           1       0.19      0.19      0.19       119
           2       0.25      0.25      0.25       118
           3       0.18      0.16      0.17       120
           4       0.23      0.23      0.23       121

    accuracy                           0.24       600
    macro avg      0.23      0.24      0.23       600
    weighted avg   0.23      0.24      0.24       600


<summary>ğŸ”¢ Confusion Matrix</summary>

     43 18 17 19 25
     29 23 20 22 25
     20 26 29 22 21
     26 27 25 19 23
     17 29 23 24 28

---

#### ğŸ§  MLPClassifier  
**Accuracy:** `0.17`  
<summary>ğŸ“‹ Classification Report</summary>

               precision    recall  f1-score   support

           0       0.20      0.18      0.19       122
           1       0.17      0.15      0.16       119
           2       0.24      0.24      0.24       118
           3       0.12      0.12      0.12       120
           4       0.13      0.16      0.15       121

    accuracy                           0.17       600
    macro avg      0.17      0.17      0.17       600
    weighted avg   0.17      0.17      0.17       600

<summary>ğŸ”¢ Confusion Matrix</summary>

     22 20 23 30 27
     18 18 19 19 45
     25 20 28 28 17
     26 22 24 15 33
     21 23 23 35 19

---

#### ğŸŒ€ SVM  
**Accuracy:** `0.1683333`  
<summary>ğŸ“‹ Classification Report</summary>

               precision    recall  f1-score   support

           0       0.19      0.17      0.18       122
           1       0.21      0.21      0.21       119
           2       0.18      0.13      0.15       118
           3       0.13      0.14      0.14       120
           4       0.15      0.19      0.17       121

    accuracy                           0.17       600
    macro avg      0.17      0.17      0.17       600
    weighted avg   0.17      0.17      0.17       600

<summary>ğŸ”¢ Confusion Matrix</summary>

     22 20 23 30 27
     18 18 19 19 45
     25 20 28 28 17
     26 22 24 15 33
     21 23 23 35 19

---

#### ğŸ”¬ LDA  
**Accuracy:** `0.18166666`  
<summary>ğŸ“‹ Classification Report</summary>

               precision    recall  f1-score   support

           0       0.17      0.11      0.13       122
           1       0.18      0.26      0.22       119
           2       0.22      0.02      0.03       118
           3       0.17      0.23      0.20       120
           4       0.19      0.29      0.23       121

    accuracy                           0.18       600
    macro avg      0.19      0.18      0.16       600
    weighted avg   0.19      0.18      0.16       600

<summary>ğŸ”¢ Confusion Matrix</summary>

     13 34  4 38 33
     16 31  1 37 34
     18 29  2 25 44
     21 33  0 28 38
     10 42  2 32 35

---

#### âœ… ëª¨ë¸ë³„ ì‹¤í—˜ ê²°ê³¼

| ëª¨ë¸               | Accuracy | Macro F1 |
|--------------------|----------|----------|
| LogisticRegression | 0.18     | 0.16     |    
| RandomForest       | 0.20     | 0.19     |       
| CatBoost           | 0.20     | 0.20     |        
| XGBoost            | **0.24** | **0.23** |             
| MLPClassifier      | 0.17     | 0.17     |         
| SVM                | 0.17     | 0.17     |    
| LDA                | 0.18     | 0.16     |      

- **ìµœê³  ì„±ëŠ¥ ëª¨ë¸:** XGBoost (Accuracy: 0.2367, Macro F1: 0.23)  
- **ë¶„ì„:** ì˜ˆì¸¡ ë‚œì´ë„ê°€ ë†’ì•„ ì „ë°˜ì ìœ¼ë¡œ ì •í™•ë„ì˜ í–¥ìƒ í­ì´ ë¯¸ë¯¸í•˜ë‚˜, XGBoost ì•Œê³ ë¦¬ì¦˜ì˜ ì •í™•ë„ê°€ ê°€ì¥ ë†’ê²Œ ë‚˜ì™”ìŒ.

### 2. **ë‹¤ì–‘í•œ ì „ì²˜ë¦¬ ì ìš©**
   - ê²°ì¸¡ì¹˜ ì²˜ë¦¬, ì´ìƒì¹˜ ì²˜ë¦¬, ë°ì´í„° íƒ€ì… ë³€í™˜ ë“±

### 3. **Feature Engineering**
   - ê²°ì¸¡ì¹˜ ì²˜ë¦¬, ì´ìƒì¹˜ ì²˜ë¦¬, ë°ì´í„° íƒ€ì… ë³€í™˜ ë“±

## ğŸ”— ì°¸ê³  ìë£Œ
- [ë°ì´í„° ì¶œì²˜ ë§í¬]
- [ì°¸ê³  ë…¼ë¬¸/ìë£Œ]

## ğŸš© ì‹¤í–‰ ë°©ë²• 
```bash
# í™˜ê²½ì„¤ì •
pip install -r requirements.txt
