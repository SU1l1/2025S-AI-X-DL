# stress_predict_rf.py

import pandas as pd
from sklearn.model_selection import train_test_split
import xgboost as xgb
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt

# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (í˜„ì¬ ë””ë ‰í† ë¦¬ì— ìˆëŠ” íŒŒì¼ ì‚¬ìš©)
df = pd.read_csv("train.csv")

# 2. ì‚¬ìš©í•  featureì™€ target ì„ íƒ
X = df[['Avg_Working_Hours_Per_Day', 'Sleeping_Habit']]
y = df['Stress_Level']

# 3. target ë¼ë²¨ ì¸ì½”ë”© (1~5 â†’ 0~4)
y_encoded = y - 1

# 4. í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded, test_size=0.2, random_state=42
)

# 5. ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ
model = xgb.XGBClassifier(
    objective='multi:softmax',
    num_class=5,
    eval_metric='mlogloss',
    use_label_encoder=False
)
model.fit(X_train, y_train)

# 6. ì˜ˆì¸¡ ë° í‰ê°€
y_pred_encoded = model.predict(X_test)
y_pred = y_pred_encoded + 1  # ë‹¤ì‹œ 1~5ë¡œ ë³µì›
y_test_orig = y_test + 1

print("âœ… Accuracy:", accuracy_score(y_test_orig, y_pred))
print("\nğŸ“‹ Classification Report:")
print(classification_report(y_test_orig, y_pred))

# 7. Feature Importance ì‹œê°í™”
xgb.plot_importance(model, height=0.5)
plt.title("XGBoost Feature Importance (2 features only)")
plt.tight_layout()
plt.show()
